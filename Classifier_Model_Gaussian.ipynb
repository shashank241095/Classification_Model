{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import Required Packages\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = 0\n",
    "dat = []\n",
    "\n",
    "\"\"\"\n",
    "Reading Data in List.\n",
    "\n",
    "\"\"\"\n",
    "with open('spambase.data', mode='r') as f:\n",
    "    line_count = 0\n",
    "    for row in f:\n",
    "        l = row.strip().split(\",\")\n",
    "        l = map(float, l)\n",
    "        # print l\n",
    "        dat.append(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dividing datasets by Classes which is {1:attributes and 0:attributes}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def sep_class(train1):\n",
    "    class_mapping = {}\n",
    "\n",
    "    for i in range(len(train1)):\n",
    "        temp = train1[i]\n",
    "        cl = temp[-1]\n",
    "        val = temp[:-1]\n",
    "\n",
    "        if cl not in class_mapping:\n",
    "            class_mapping[cl] = []\n",
    "        class_mapping[cl].append(val)\n",
    "    return class_mapping\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Finding mean and std. Deviation function for Gussian distribution.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def mean(listt):\n",
    "    return sum(listt) / float(len(listt))\n",
    "\n",
    "\n",
    "\n",
    "def stdev(numbers):\n",
    "    cal_mean = mean(numbers)\n",
    "    variance = sum([pow(x - cal_mean, 2) for x in numbers]) / float(len(numbers) - 1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper function to calculate mean and variance for each class (column wise) \n",
    "like '(mean,Std_deviation)' tuples of 57 features and 2 classes each which \n",
    "is 114 values.\n",
    "\"\"\"\n",
    "def helper(dataset):\n",
    "    mean_var_dict = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    return mean_var_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate Gaussian Density and meanwhile performed smoothing for extremely small Values Not used add one smoothing \n",
    "because  most of thethe integers Values of datasets are smaller than 1 which would might distort the Model\n",
    "\"\"\"\n",
    "\n",
    "def density_Prob(x, mean, stdev):\n",
    "    if (mean == 0.0 or stdev == 0.0):\n",
    "        mean += 0.0000000001                                # Smoothing for some very small value\n",
    "        \n",
    "        stdev += 0.00000000001                              # Smoothing for some very small value\n",
    "    exponent = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2))))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding and multiplying the pdf(each attribute of test input) to compare the class\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def calculateClassProbabilities(mean_var_dict, inputt):\n",
    "    probabilities = {}\n",
    "    for classValue, value in mean_var_dict.iteritems():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(value)):\n",
    "            mean, stdev = value[i]\n",
    "            x = inputt[i]\n",
    "            probabilities[classValue] *= density_Prob(x, mean, stdev)\n",
    "    return probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Choosing the best label by comparing class1_prob < class2_prob tag class2\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def predict(summaries, inputt):\n",
    "    inputt=inputt[:-1]\n",
    "    probabilities = calculateClassProbabilities(summaries, inputt)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    \n",
    "    \"\"\"\n",
    "    Finding Best class Probability by comparing for class\n",
    "    \"\"\"\n",
    "    for classValue, probability in probabilities.iteritems():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "\n",
    "\"\"\"\n",
    "storing all prdicted Values for each class in list named Predictions\n",
    "\"\"\"\n",
    "def Calculate_Predictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "To calculate False positive , False Negative and Error tags\n",
    "\n",
    "\"\"\"\n",
    "def Calculate_Accuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    fp=0\n",
    "    totalfp=0\n",
    "    totalfn=0\n",
    "    fn=0\n",
    "    for i in range(len(testSet)):\n",
    "        \n",
    "        \"\"\"\n",
    "            Counting False Positive\n",
    "        \"\"\"\n",
    "\n",
    "        if testSet[i][-1] == 0:\n",
    "            if testSet[i][-1] != predictions[i]:\n",
    "                fp=fp+1\n",
    "            totalfp=totalfp+1\n",
    "            \n",
    "        \"\"\"\n",
    "        Counting False Negative\n",
    "        \"\"\"\n",
    "        if testSet[i][-1] == 1:\n",
    "            if testSet[i][-1] != predictions[i]:\n",
    "                fn = fn + 1\n",
    "            totalfn = totalfn + 1\n",
    "        \"\"\"\n",
    "            Calculating accuracy for Error Rate\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "\n",
    "    return (correct / float(len(testSet))) * 100.0,(fp/float(totalfp)),(fn/float(totalfn))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "K-Folds Cross Validation k=5\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "random.shuffle(dat)\n",
    "k = 5\n",
    "\n",
    "part = math.ceil(len(dat) / 5)\n",
    "itemp = 0\n",
    "train1=[]\n",
    "test1=[]\n",
    "sum_error=0\n",
    "Elist=[]\n",
    "Flist=[]\n",
    "Nlist=[]\n",
    "for i in range(0, 5):\n",
    "\n",
    "    l=0\n",
    "\n",
    "    train1=[]\n",
    "    test1=[]\n",
    "\n",
    "\n",
    "    testfig = []\n",
    "    trainfig = []\n",
    "    part = int(part)\n",
    "    l = int((i + 1) * part)\n",
    "\n",
    "    testfig = dat[itemp:l]\n",
    "\n",
    "    trainfig = [item for item in dat if item not in testfig]\n",
    "\n",
    "    itemp = l\n",
    "\n",
    "    \"\"\"\n",
    "    Splitting Train and Test by one Part k for test data and rest as training data\n",
    "    \"\"\"\n",
    "    train1,test1=trainfig,testfig  \n",
    "\n",
    "    class_mapping = sep_class(train1)\n",
    "    \n",
    "    \"\"\"\n",
    "    (Mean,Variance) Dictionary by class 0 and 1 mean_var_dict={} \n",
    "    \"\"\"\n",
    "    mean_var_dict = {}\n",
    "    for classValue, instances in class_mapping.iteritems():\n",
    "        mean_var_dict[classValue] = helper(instances)\n",
    "\n",
    "    predictions = Calculate_Predictions(mean_var_dict, test1)\n",
    "\n",
    "    accuracy,false_positve,false_negative = Calculate_Accuracy(test1, predictions)\n",
    "\n",
    "    error=100-accuracy\n",
    "\n",
    "    sum_error=error+sum_error    # add errors to find average\n",
    "\n",
    "    #print \"Error rates:\",error\n",
    "    #print \"false positive\",false_positve\n",
    "    #print \"false negative\",false_negative\n",
    "\n",
    "    Elist.append(error)\n",
    "    Flist.append(false_positve)\n",
    "    Nlist.append(false_negative)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 False Positive   False Negative     Error Rate\n",
      "Fold                                                           \n",
      "1                0.248695652174  0.0550724637681  17.6086956522\n",
      "2                 0.27255985267  0.0742705570292  19.1304347826\n",
      "3                0.284946236559  0.0303867403315  18.4782608696\n",
      "4                0.264705882353  0.0263157894737  17.6086956522\n",
      "5               0.0994371482176   0.108527131783  10.3260869565\n",
      "6     Average Error Rate in (%)               is  16.6304347826\n",
      "Accuracy of the Model with last fold is  89.6739130435 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using Pandas Framework to form the Table\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "Lab_list=[\"Average Error Rate in (%)\" ,\"  is\" ,sum_error/5]\n",
    "\n",
    "\n",
    "\n",
    "labels=(\"False Positive\",\"False Negative\", \"Error Rate\")\n",
    "\n",
    "\n",
    "Elist=map(str,Elist)\n",
    "Flist=map(str,Flist)\n",
    "Nlist=map(str,Nlist)\n",
    "Lab_list=map(str,Lab_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p=zip(Flist,Nlist,Elist)\n",
    "\n",
    "Lab_list=tuple(Lab_list)\n",
    "\n",
    "\n",
    "p.append(Lab_list)\n",
    "\n",
    "\n",
    "table=pd.DataFrame.from_records(p,columns=labels)\n",
    "\n",
    "table.index.name=\"Fold\"\n",
    "table.index+=1\n",
    "\n",
    "\n",
    "print table\n",
    "\n",
    "print \"Accuracy of the Model with last fold is \",accuracy,\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
